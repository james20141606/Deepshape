{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Share/home/shibinbin/projects/DeepShape\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Lambda, Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import Concatenate, Add\n",
    "from keras.layers.convolutional import Conv1D, Conv2D, UpSampling1D, UpSampling2D\n",
    "from keras.layers.pooling import MaxPooling1D, MaxPooling2D, GlobalMaxPooling1D, GlobalMaxPooling2D, AveragePooling1D\n",
    "from keras.regularizers import l2, l1, l1_l2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras import backend as K\n",
    "\n",
    "def set_keras_num_threads(n_threads):\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.intra_op_parallelism_threads = n_threads\n",
    "    config.inter_op_parallelism_threads = n_threads\n",
    "    K.set_session(tf.Session(config=config))\n",
    "    \n",
    "set_keras_num_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RNA\n",
    "from forgi.graph import bulge_graph\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = np.array(list('AUCG'))\n",
    "sequences = np.take(alphabet, np.random.randint(4, size=(100, 60)))\n",
    "sequences_str = [''.join(a) for a in sequences]\n",
    "\n",
    "structures = []\n",
    "energies = []\n",
    "for seq in sequences_str:\n",
    "    structure, energy = RNA.fold(seq)\n",
    "    structures.append(structure)\n",
    "    energies.append(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: ['G' 'A' 'C' 'A' 'G' 'C' 'A' 'U' 'G' 'G' 'C' 'U' 'G' 'A' 'A' 'C' 'U' 'C'\n",
      " 'A' 'C' 'U' 'U' 'U' 'C' 'A' 'A' 'C' 'G' 'C' 'G' 'G' 'A' 'A' 'C' 'U' 'C'\n",
      " 'G' 'C' 'U' 'G' 'C' 'C' 'C' 'A' 'A' 'G' 'U' 'A' 'A' 'G' 'C' 'A' 'U' 'C'\n",
      " 'C' 'C' 'C' 'A' 'G' 'U']\n",
      "Structure: ..((((...))))..((.((((.....(((.....))).....)))).))..........\n",
      "[[1], [0, 2], [1, 3, 12], [2, 4, 11], [3, 5, 10], [4, 6, 9], [5, 7], [6, 8], [7, 9], [8, 5, 10], [9, 4, 11], [10, 3, 12], [11, 2, 13], [12, 14], [13, 15], [14, 16, 49], [15, 17, 48], [16, 18], [17, 19, 46], [18, 20, 45], [19, 21, 44], [20, 22, 43], [21, 23], [22, 24], [23, 25], [24, 26], [25, 27], [26, 28, 37], [27, 29, 36], [28, 30, 35], [29, 31], [30, 32], [31, 33], [32, 34], [33, 35], [34, 29, 36], [35, 28, 37], [36, 27, 38], [37, 39], [38, 40], [39, 41], [40, 42], [41, 43], [42, 21, 44], [43, 20, 45], [44, 19, 46], [45, 18, 47], [46, 48], [47, 16, 49], [48, 15, 50], [49, 51], [50, 52], [51, 53], [52, 54], [53, 55], [54, 56], [55, 57], [56, 58], [57, 59], [58]]\n",
      "node_features: shape = (180, 4)\n",
      "node_ranges: shape = (3, 2)\n",
      "neighbor_indices: shape = (450,)\n",
      "neighbor_indices_ranges: shape = (3, 2)\n"
     ]
    }
   ],
   "source": [
    "def structure_to_adj_list(structure):\n",
    "    '''\n",
    "    Parameters:\n",
    "        structure: str\n",
    "            Dot-bracket representation of RNA secondary structure\n",
    "    Returns:\n",
    "        adj_list: list\n",
    "            Each element is a list of tuples (node_index, edge_index)\n",
    "        edge_data: array\n",
    "            Shape: [length, 3]\n",
    "            One-hot coding of edges\n",
    "            10: adjacent connection\n",
    "            01: base pair\n",
    "    '''\n",
    "    L = len(structure)\n",
    "    adj_list = [[] for i in range(L)]\n",
    "    edge_data = []\n",
    "    S = []\n",
    "    edge_index = 0\n",
    "    for i in range(L):\n",
    "        if i > 0:\n",
    "            adj_list[i].append([i - 1, edge_index])\n",
    "            adj_list[i - 1].append([i, edge_index])\n",
    "            edge_data.append([1, 0])\n",
    "            edge_index += 1\n",
    "        if structure[i] == '(':\n",
    "            S.append(i)\n",
    "        elif structure[i] == ')':\n",
    "            if len(S) == 0:\n",
    "                raise ValueError('Extra \")\" found in dot-bracket at position {}'.format(i))\n",
    "            else:\n",
    "                j = S.pop()\n",
    "                adj_list[i].append([j, edge_index])\n",
    "                adj_list[j].append([i, edge_index])\n",
    "                edge_data.append([0, 1])\n",
    "                edge_index += 1\n",
    "    if len(S) != 0:\n",
    "        raise ValueError('Extra \"(\" found in dot-bracket at position {}'.format(S[0]))\n",
    "    edge_data = np.asarray(edge_data, dtype=np.int32)\n",
    "    adj_list = [np.asarray(a, dtype=np.int32) for a in adj_list]\n",
    "    \n",
    "    return adj_list, edge_data\n",
    "\n",
    "def graph_featurize(node_data, adj_lists, max_deg=3, digraph=False):\n",
    "    '''\n",
    "    Parameters:\n",
    "        node_data: list\n",
    "            Each element is an array of shape [length, n_channels]\n",
    "            List length: n_samples\n",
    "        adj_lists: list\n",
    "            A list of tuples: (start_node, end_node)\n",
    "            List length: n_samples\n",
    "    Returns:\n",
    "        node_features: list\n",
    "            Copy from input argument node_data\n",
    "        neighbor_features: list\n",
    "            Each element is an array of shape [n_nodes_deg, deg]\n",
    "            List length: max_deg + 1\n",
    "        node_ranges: list\n",
    "            Each element is an array of shape [n_samples, 2]\n",
    "            node_ranges[i][j, 0]: start index of node j of degree i\n",
    "            node_ranges[i][j, 1]: end index of node j of degree i\n",
    "            List length: max_deg + 1\n",
    "    '''\n",
    "    n_samples = len(adj_lists)\n",
    "    neighbor_features = [[] for i in range(max_deg + 1)]\n",
    "    for i_sample in range(n_samples):\n",
    "        neighbor_features_s = [[] for i in range(max_deg + 1)]\n",
    "        for i_node, adj_nodes in enumerate(adj_lists[i_sample]):\n",
    "            deg = len(adj_nodes)\n",
    "            if deg > max_deg:\n",
    "                raise ValueError('number of adjacent nodes of node {} in sample {} is larger than maximum degree {}'.format(\n",
    "                    i_node, i_sample, max_deg))\n",
    "            neighbor_features_s[deg].append(node_data[i_sample][adj_nodes])\n",
    "        for deg in range(max_deg + 1):\n",
    "            if len(neighbor_features_s[deg]) > 0:\n",
    "                neighbor_features_s[deg] = np.row_stack(neighbor_features_s[deg])\n",
    "            else:\n",
    "                neighbor_features_s[deg] = np.empty((0, deg), dtype=np.int32)\n",
    "            neighbor_features[deg].append(neighbor_features_s[deg])\n",
    "    node_ranges = []\n",
    "    for deg in range(max_deg + 1):\n",
    "        node_ranges_d = np.empty((n_samples, 2), dtype=np.int32)\n",
    "        n_nodes_deg = np.asarray([a.shape[0] for a in neighbor_features[deg]], dtype=np.int32)\n",
    "        node_ranges_d[:, 1] = np.cumsum(n_nodes_deg)\n",
    "        node_ranges_d[:, 0] = node_ranges_d[:, 1] - n_nodes_deg\n",
    "        node_ranges.append(node_ranges_d)\n",
    "        neighbor_features[deg] = np.concatenate(neighbor_features[deg], axis=0)\n",
    "    r = {\n",
    "        'node_features': node_data,\n",
    "        'neighbor_features': neighbor_features,\n",
    "        'node_ranges': node_ranges\n",
    "    }\n",
    "    return r\n",
    "\n",
    "def graph_featurize(node_data, adj_lists, max_deg=3, digraph=False):\n",
    "    '''\n",
    "    Parameters:\n",
    "        node_data: list\n",
    "            Each element is an array of shape [length, n_channels]\n",
    "            List length: n_samples\n",
    "        edge_data: list\n",
    "            Shape: [n_edges, n_channels_edge]\n",
    "            List length: n_samples\n",
    "        adj_lists: list\n",
    "            adj_lists[i][j][0]: index of adjacent node j of node i in node_data[i]\n",
    "            adj_lists[i][j][1]: index of edge (i, j) in edge_data[i]\n",
    "            List length: n_samples\n",
    "    Returns:\n",
    "        node_features: array\n",
    "            Shape: [n_nodes, n_channels]\n",
    "        node_ranges: array\n",
    "            Shape: [n_samples, 2]\n",
    "            node_ranges[i, 0]: start index of sample i in node_features\n",
    "            node_ranges[i, 1]: end index of sample i in node_features\n",
    "        neighbor_indices: array\n",
    "            Shape [n_nodes_deg*deg]*max_deg\n",
    "            Indices of neighbor nodes of degree deg in node_features (first axis)\n",
    "        neighbor_indices_ranges: array\n",
    "            Shape: [max_deg, 2]\n",
    "            neighbor_indices_ranges[deg, 0]: start index of degree deg in neighbor_indices\n",
    "            neighbor_indices_ranges[deg, 1]: end index of degree deg in neighbor_indices\n",
    "    '''\n",
    "    n_samples = len(node_data)\n",
    "    graph_sizes = np.asarray([len(a) for a in node_data], dtype=np.int32)\n",
    "    node_features = np.concatenate(node_data, axis=0)\n",
    "    \n",
    "    node_ranges = np.zeros((n_samples, 2), dtype=np.int32)\n",
    "    node_ranges[:, 1] = np.cumsum(graph_sizes)\n",
    "    node_ranges[:, 0] = node_ranges[:, 1] - graph_sizes\n",
    "    \n",
    "    neighbor_indices = [[] for i in range(max_deg)]\n",
    "    for i_sample in range(n_samples):\n",
    "        neighbor_indices_s = [[] for i in range(max_deg)]\n",
    "        for i_node, adj_nodes in enumerate(adj_lists[i_sample]):\n",
    "            deg = len(adj_nodes)\n",
    "            if deg > max_deg:\n",
    "                raise ValueError('number of adjacent nodes of node {} in sample {} is larger than maximum degree {}'.format(\n",
    "                    i_node, i_sample, max_deg))\n",
    "            neighbor_indices_s[deg - 1].append(adj_nodes)\n",
    "        for deg in range(max_deg):\n",
    "            if len(neighbor_indices_s[deg]) > 0:\n",
    "                neighbor_indices_s[deg] = np.concatenate(neighbor_indices_s[deg])\n",
    "                neighbor_indices_s[deg] += node_ranges[i_sample, 0]\n",
    "            else:\n",
    "                neighbor_indices_s[deg] = np.empty(0, dtype=np.int32)\n",
    "            neighbor_indices[deg].append(neighbor_indices_s[deg])\n",
    "    for deg in range(max_deg):\n",
    "        neighbor_indices[deg] = np.concatenate(neighbor_indices[deg])\n",
    "    neighbor_indices_lengths = np.asarray([len(a) for a in neighbor_indices], dtype=np.int32)\n",
    "    neighbor_indices_ranges = np.zeros((max_deg, 2), dtype=np.int32)\n",
    "    neighbor_indices_ranges[:, 1] = np.cumsum(neighbor_indices_lengths)\n",
    "    neighbor_indices_ranges[:, 0] = neighbor_indices_ranges[:, 1] - neighbor_indices_lengths\n",
    "    neighbor_indices = np.concatenate(neighbor_indices)\n",
    "    r = {\n",
    "        'node_features': node_features,\n",
    "        'node_ranges': node_ranges,\n",
    "        'neighbor_indices': neighbor_indices,\n",
    "        'neighbor_indices_ranges': neighbor_indices_ranges,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "sequence_str = sequences_str[0]\n",
    "sequence = sequences[0]\n",
    "structure = structures[0]\n",
    "node_data = (sequence.reshape((-1, 1)) == alphabet.reshape((1, -1))).astype(np.int32)\n",
    "print('Sequence:', sequence)\n",
    "print('Structure:', structure)\n",
    "adj_list = structure_to_adj_list(structure)\n",
    "print(adj_list)\n",
    "\n",
    "node_data = []\n",
    "adj_lists = []\n",
    "for i in range(3):\n",
    "    node_data.append((sequences[i].reshape((-1, 1)) == alphabet.reshape((1, -1))).astype(np.int32))\n",
    "    adj_lists.append(structure_to_adj_list(structures[i]))\n",
    "graph_features = graph_featurize(node_data, adj_lists, max_deg=3)\n",
    "for key, value in graph_features.items():\n",
    "    print('{}: shape = {}'.format(key, value.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree = 0\n",
      "[ 0 60]\n",
      "degree = 1\n",
      "[ 60 120]\n",
      "degree = 2\n",
      "[120 180]\n"
     ]
    }
   ],
   "source": [
    "for deg, node_ranges in enumerate(graph_features['node_ranges']):\n",
    "    print('degree = {}'.format(deg))\n",
    "    print(node_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree = 1, shape = (6, 1)\n",
      "degree = 2, shape = (78, 2)\n",
      "degree = 3, shape = (96, 3)\n"
     ]
    }
   ],
   "source": [
    "for deg, neighbor_indices_range in enumerate(graph_features['neighbor_indices_ranges']):\n",
    "    deg += 1\n",
    "    start, end = neighbor_indices_range\n",
    "    neighbor_indices_deg = graph_features['neighbor_indices'][start:end].reshape((-1, deg))\n",
    "    print('degree = {}, shape = {}'.format(deg, neighbor_indices_deg.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3, 12],\n",
       "       [ 2,  4, 11],\n",
       "       [ 3,  5, 10],\n",
       "       [ 4,  6,  9],\n",
       "       [ 8,  5, 10],\n",
       "       [ 9,  4, 11],\n",
       "       [10,  3, 12],\n",
       "       [11,  2, 13],\n",
       "       [14, 16, 49],\n",
       "       [15, 17, 48]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor_indices_deg[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(Layer):\n",
    "    \"\"\"Wraps arbitrary expression as a `Layer` object.\n",
    "\n",
    "    # Examples\n",
    "\n",
    "    ```python\n",
    "        # add a x -> x^2 layer\n",
    "        model.add(Lambda(lambda x: x ** 2))\n",
    "    ```\n",
    "    ```python\n",
    "        # add a layer that returns the concatenation\n",
    "        # of the positive part of the input and\n",
    "        # the opposite of the negative part\n",
    "\n",
    "        def antirectifier(x):\n",
    "            x -= K.mean(x, axis=1, keepdims=True)\n",
    "            x = K.l2_normalize(x, axis=1)\n",
    "            pos = K.relu(x)\n",
    "            neg = K.relu(-x)\n",
    "            return K.concatenate([pos, neg], axis=1)\n",
    "\n",
    "        def antirectifier_output_shape(input_shape):\n",
    "            shape = list(input_shape)\n",
    "            assert len(shape) == 2  # only valid for 2D tensors\n",
    "            shape[-1] *= 2\n",
    "            return tuple(shape)\n",
    "\n",
    "        model.add(Lambda(antirectifier,\n",
    "                         output_shape=antirectifier_output_shape))\n",
    "    ```\n",
    "\n",
    "    # Arguments\n",
    "        function: The function to be evaluated.\n",
    "            Takes input tensor as first argument.\n",
    "        output_shape: Expected output shape from function.\n",
    "            Only relevant when using Theano.\n",
    "            Can be a tuple or function.\n",
    "            If a tuple, it only specifies the first dimension onward;\n",
    "                 sample dimension is assumed either the same as the input:\n",
    "                 `output_shape = (input_shape[0], ) + output_shape`\n",
    "                 or, the input is `None` and\n",
    "                 the sample dimension is also `None`:\n",
    "                 `output_shape = (None, ) + output_shape`\n",
    "            If a function, it specifies the entire shape as a function of the\n",
    "            input shape: `output_shape = f(input_shape)`\n",
    "        arguments: optional dictionary of keyword arguments to be passed\n",
    "            to the function.\n",
    "\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument input_shape\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "\n",
    "    # Output shape\n",
    "        Specified by `output_shape` argument\n",
    "        (or auto-inferred when using TensorFlow).\n",
    "    \"\"\"\n",
    "\n",
    "    @interfaces.legacy_lambda_support\n",
    "    def __init__(self, function, output_shape=None,\n",
    "                 mask=None, arguments=None, **kwargs):\n",
    "        super(Lambda, self).__init__(**kwargs)\n",
    "        self.function = function\n",
    "        self.arguments = arguments if arguments else {}\n",
    "        if mask is not None:\n",
    "            self.supports_masking = True\n",
    "        self.mask = mask\n",
    "\n",
    "        if output_shape is None:\n",
    "            self._output_shape = None\n",
    "        elif isinstance(output_shape, (tuple, list)):\n",
    "            self._output_shape = tuple(output_shape)\n",
    "        else:\n",
    "            if not callable(output_shape):\n",
    "                raise TypeError('In Lambda, `output_shape` '\n",
    "                                'must be a list, a tuple, or a function.')\n",
    "            self._output_shape = output_shape\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self._output_shape is None:\n",
    "            # With TensorFlow, we can infer the output shape directly:\n",
    "            if K.backend() == 'tensorflow':\n",
    "                if isinstance(input_shape, list):\n",
    "                    xs = [K.placeholder(shape=shape) for shape in input_shape]\n",
    "                    x = self.call(xs)\n",
    "                else:\n",
    "                    x = K.placeholder(shape=input_shape)\n",
    "                    x = self.call(x)\n",
    "                if isinstance(x, list):\n",
    "                    return [K.int_shape(x_elem) for x_elem in x]\n",
    "                else:\n",
    "                    return K.int_shape(x)\n",
    "            # Otherwise, we default to the input shape.\n",
    "            warnings.warn('`output_shape` argument not specified for layer {} '\n",
    "                          'and cannot be automatically inferred '\n",
    "                          'with the Theano backend. '\n",
    "                          'Defaulting to output shape `{}` '\n",
    "                          '(same as input shape). '\n",
    "                          'If the expected output shape is different, '\n",
    "                          'specify it via the `output_shape` argument.'\n",
    "                          .format(self.name, input_shape))\n",
    "            return input_shape\n",
    "        elif isinstance(self._output_shape, (tuple, list)):\n",
    "            if isinstance(input_shape, list):\n",
    "                num_samples = input_shape[0][0]\n",
    "            else:\n",
    "                num_samples = input_shape[0] if input_shape else None\n",
    "            return (num_samples,) + tuple(self._output_shape)\n",
    "        else:\n",
    "            shape = self._output_shape(input_shape)\n",
    "            if not isinstance(shape, (list, tuple)):\n",
    "                raise ValueError('`output_shape` function must return a tuple or a list of tuples.')\n",
    "            if isinstance(shape, list):\n",
    "                if isinstance(shape[0], int) or shape[0] is None:\n",
    "                    shape = tuple(shape)\n",
    "            return shape\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        arguments = self.arguments\n",
    "        if has_arg(self.function, 'mask'):\n",
    "            arguments['mask'] = mask\n",
    "        return self.function(inputs, **arguments)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if callable(self.mask):\n",
    "            return self.mask(inputs, mask)\n",
    "        return self.mask\n",
    "\n",
    "    def get_config(self):\n",
    "        if isinstance(self.function, python_types.LambdaType):\n",
    "            function = func_dump(self.function)\n",
    "            function_type = 'lambda'\n",
    "        else:\n",
    "            function = self.function.__name__\n",
    "            function_type = 'function'\n",
    "\n",
    "        if isinstance(self._output_shape, python_types.LambdaType):\n",
    "            output_shape = func_dump(self._output_shape)\n",
    "            output_shape_type = 'lambda'\n",
    "        elif callable(self._output_shape):\n",
    "            output_shape = self._output_shape.__name__\n",
    "            output_shape_type = 'function'\n",
    "        else:\n",
    "            output_shape = self._output_shape\n",
    "            output_shape_type = 'raw'\n",
    "\n",
    "        config = {'function': function,\n",
    "                  'function_type': function_type,\n",
    "                  'output_shape': output_shape,\n",
    "                  'output_shape_type': output_shape_type,\n",
    "                  'arguments': self.arguments}\n",
    "        base_config = super(Lambda, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, custom_objects=None):\n",
    "        config = config.copy()\n",
    "        globs = globals()\n",
    "        if custom_objects:\n",
    "            globs = dict(list(globs.items()) + list(custom_objects.items()))\n",
    "        function_type = config.pop('function_type')\n",
    "        if function_type == 'function':\n",
    "            # Simple lookup in custom objects\n",
    "            function = deserialize_keras_object(\n",
    "                config['function'],\n",
    "                custom_objects=custom_objects,\n",
    "                printable_module_name='function in Lambda layer')\n",
    "        elif function_type == 'lambda':\n",
    "            # Unsafe deserialization from bytecode\n",
    "            function = func_load(config['function'], globs=globs)\n",
    "        else:\n",
    "            raise TypeError('Unknown function type:', function_type)\n",
    "\n",
    "        output_shape_type = config.pop('output_shape_type')\n",
    "        if output_shape_type == 'function':\n",
    "            # Simple lookup in custom objects\n",
    "            output_shape = deserialize_keras_object(\n",
    "                config['output_shape'],\n",
    "                custom_objects=custom_objects,\n",
    "                printable_module_name='output_shape function in Lambda layer')\n",
    "        elif output_shape_type == 'lambda':\n",
    "            # Unsafe deserialization from bytecode\n",
    "            output_shape = func_load(config['output_shape'], globs=globs)\n",
    "        else:\n",
    "            output_shape = config['output_shape']\n",
    "\n",
    "        # If arguments were numpy array, they have been saved as\n",
    "        # list. We need to recover the ndarray\n",
    "        if 'arguments' in config:\n",
    "            for key in config['arguments']:\n",
    "                if isinstance(config['arguments'][key], dict):\n",
    "                    arg_dict = config['arguments'][key]\n",
    "                    if 'type' in arg_dict and arg_dict['type'] == 'ndarray':\n",
    "                        # Overwrite the argument with its numpy translation\n",
    "                        config['arguments'][key] = np.array(arg_dict['value'])\n",
    "\n",
    "        config['function'] = function\n",
    "        config['output_shape'] = output_shape\n",
    "        return cls(**config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(Layer):\n",
    "    def __init__(self, units, max_deg, \n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(Dense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.max_deg = max_deg\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "        self.supports_masking = False\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 2\n",
    "        input_dim = input_shape[-1]\n",
    "\n",
    "        # kernel[0 - max_deg]: kernel for neighbor nodes\n",
    "        # kernel[max_deg + 1]: kernel for node itself\n",
    "        self.kernel = self.add_weight(shape=(self.max_deg + 2, input_dim, self.units),\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_features, neighbor_features, neighbor_ranges = inputs\n",
    "        summed_outputs = []\n",
    "        for deg in range(self.max_deg + 1):\n",
    "            summed_outputs.append(K.sum(neighbor_features[deg], axis=-1))\n",
    "        summed_outputs.append(node_features)\n",
    "        output = K.concatenate(summed_outputs, axis=1)\n",
    "        output = K.dot(output, self.kernel)\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) >= 2\n",
    "        assert input_shape[-1]\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] = self.units\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'activation': activations.serialize(self.activation),\n",
    "            'use_bias': self.use_bias,\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
    "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
    "        }\n",
    "        base_config = super(Dense, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import marshal\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_dump(func):\n",
    "    \"\"\"Serializes a user defined function.\n",
    "\n",
    "    # Arguments\n",
    "        func: the function to serialize.\n",
    "\n",
    "    # Returns\n",
    "        A tuple `(code, defaults, closure)`.\n",
    "    \"\"\"\n",
    "    raw_code = marshal.dumps(func.__code__)\n",
    "    code = codecs.encode(raw_code, 'base64').decode('ascii')\n",
    "    defaults = func.__defaults__\n",
    "    if func.__closure__:\n",
    "        closure = tuple(c.cell_contents for c in func.__closure__)\n",
    "    else:\n",
    "        closure = None\n",
    "    return code, defaults, closure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4wQAAAAAAAAADwAAAAcAAABDAAAAc7ABAAB0AHwBgwF9BGQBZAKEAHQBfAJkAxcAgwFEAIMBfQV4\n",
      "3HQBfASDAUQAXdB9BmQEZAKEAHQBfAJkAxcAgwFEAIMBfQd4UHQCfAF8BhkAgwFEAF1AXAJ9CH0J\n",
      "dAB8CYMBfQp8CnwCawRyenQDZAVqBHwIfAZ8AoMDgwGCAXwHfAoZAGoFfAB8BhkAfAkZAIMBAQBx\n",
      "UFcAeGJ0AXwCZAMXAIMBRABdUn0KdAB8B3wKGQCDAWQGawRyynQGagd8B3wKGQCDAXwHfAo8AG4Y\n",
      "dAZqCGQGfApmAnQGaglkB40CfAd8CjwAfAV8ChkAagV8B3wKGQCDAQEAcaJXAHEoVwBnAH0LeJ50\n",
      "AXwCZAMXAIMBRABdjn0KdAZqCHwEZAhmAnQGaglkB40CfQx0BmoKZAlkAoQAfAV8ChkARACDAXQG\n",
      "aglkB40CfQ10BmoLfA2DAXwMZApkCoUCZANmAjwAfAxkCmQKhQJkA2YCGQB8DRgAfAxkCmQKhQJk\n",
      "BmYCPAB8C2oFfAyDAQEAdAZqDHwFfAoZAGQGZAuNAnwFfAo8AJABcQ5XAHwAfAV8C2QMnAN9DnwO\n",
      "UwApDeHjAgAACiAgICBQYXJhbWV0ZXJzOgogICAgICAgIG5vZGVfZGF0YTogbGlzdAogICAgICAg\n",
      "ICAgICBFYWNoIGVsZW1lbnQgaXMgYW4gYXJyYXkgb2Ygc2hhcGUgW2xlbmd0aCwgbl9jaGFubmVs\n",
      "c10KICAgICAgICAgICAgTGlzdCBsZW5ndGg6IG5fc2FtcGxlcwogICAgICAgIGFkal9saXN0czog\n",
      "bGlzdAogICAgICAgICAgICBBIGxpc3Qgb2YgdHVwbGVzOiAoc3RhcnRfbm9kZSwgZW5kX25vZGUp\n",
      "CiAgICAgICAgICAgIExpc3QgbGVuZ3RoOiBuX3NhbXBsZXMKICAgIFJldHVybnM6CiAgICAgICAg\n",
      "bm9kZV9mZWF0dXJlczogbGlzdAogICAgICAgICAgICBDb3B5IGZyb20gaW5wdXQgYXJndW1lbnQg\n",
      "bm9kZV9kYXRhCiAgICAgICAgbmVpZ2hib3JfZmVhdHVyZXM6IGxpc3QKICAgICAgICAgICAgRWFj\n",
      "aCBlbGVtZW50IGlzIGFuIGFycmF5IG9mIHNoYXBlIFtuX25vZGVzX2RlZywgZGVnXQogICAgICAg\n",
      "ICAgICBMaXN0IGxlbmd0aDogbWF4X2RlZyArIDEKICAgICAgICBub2RlX3JhbmdlczogbGlzdAog\n",
      "ICAgICAgICAgICBFYWNoIGVsZW1lbnQgaXMgYW4gYXJyYXkgb2Ygc2hhcGUgW25fc2FtcGxlcywg\n",
      "Ml0KICAgICAgICAgICAgbm9kZV9yYW5nZXNbaV1baiwgMF06IHN0YXJ0IGluZGV4IG9mIG5vZGUg\n",
      "aiBvZiBkZWdyZWUgaQogICAgICAgICAgICBub2RlX3Jhbmdlc1tpXVtqLCAxXTogZW5kIGluZGV4\n",
      "IG9mIG5vZGUgaiBvZiBkZWdyZWUgaQogICAgICAgICAgICBMaXN0IGxlbmd0aDogbWF4X2RlZyAr\n",
      "IDEKICAgIGMBAAAAAAAAAAIAAAADAAAAUwAAAHMQAAAAZwB8AF0IfQFnAJECcQRTAKkAcgIAAAAp\n",
      "AtoCLjDaAWlyAgAAAHICAAAA+h88aXB5dGhvbi1pbnB1dC02MC1hYzE0MGQ4N2FlOWE++go8bGlz\n",
      "dGNvbXA+LAAAAHMCAAAABgB6I2dyYXBoX2ZlYXR1cml6ZS48bG9jYWxzPi48bGlzdGNvbXA+6QEA\n",
      "AABjAQAAAAAAAAACAAAAAwAAAFMAAABzEAAAAGcAfABdCH0BZwCRAnEEUwByAgAAAHICAAAAKQJy\n",
      "AwAAAHIEAAAAcgIAAAByAgAAAHIFAAAAcgYAAAAuAAAAcwIAAAAGAHpRbnVtYmVyIG9mIGFkamFj\n",
      "ZW50IG5vZGVzIG9mIG5vZGUge30gaW4gc2FtcGxlIHt9IGlzIGxhcmdlciB0aGFuIG1heGltdW0g\n",
      "ZGVncmVlIHt96QAAAAApAdoFZHR5cGXpAgAAAGMBAAAAAAAAAAIAAAAEAAAAUwAAAHMWAAAAZwB8\n",
      "AF0OfQF8AWoAZAAZAJECcQRTACkBcggAAAApAdoFc2hhcGUpAnIDAAAA2gFhcgIAAAByAgAAAHIF\n",
      "AAAAcgYAAAA+AAAAcwIAAAAGAE4pAdoEYXhpcykD2g1ub2RlX2ZlYXR1cmVz2hFuZWlnaGJvcl9m\n",
      "ZWF0dXJlc9oLbm9kZV9yYW5nZXMpDdoDbGVu2gVyYW5nZdoJZW51bWVyYXRl2gpWYWx1ZUVycm9y\n",
      "2gZmb3JtYXTaBmFwcGVuZNoCbnDaCXJvd19zdGFja9oFZW1wdHnaBWludDMy2gdhc2FycmF52gZj\n",
      "dW1zdW3aC2NvbmNhdGVuYXRlKQ/aCW5vZGVfZGF0YdoJYWRqX2xpc3Rz2gdtYXhfZGVn2gdkaWdy\n",
      "YXBo2gluX3NhbXBsZXNyDwAAANoIaV9zYW1wbGXaE25laWdoYm9yX2ZlYXR1cmVzX3PaBmlfbm9k\n",
      "ZdoJYWRqX25vZGVz2gNkZWdyEAAAANoNbm9kZV9yYW5nZXNfZNoLbl9ub2Rlc19kZWfaAXJyAgAA\n",
      "AHICAAAAcgUAAADaD2dyYXBoX2ZlYXR1cml6ZRYAAABzNgAAAAAVCAEWAQ4BFgEWAQgBCAEGAQwB\n",
      "GgESARABFAIYARoBBAESARQBHgEWASABCgEcAgIBAgEIAg==\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(codecs.encode(marshal.dumps(graph_featurize.__code__), 'base64').decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [0, 2], [1, 3, 12], [2, 4, 11], [3, 5, 10]]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.concatenate(adj_list)\n",
    "data = np.ones(len(indices), dtype=np.int32)\n",
    "lengths = np.asarray(list(map(len, adj_list)), dtype=np.int32)\n",
    "indptr = np.cumsum(lengths) - lengths\n",
    "g = csr_matrix((data, indices, indptr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x7f9dfb0052b0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolor(g.toarray(), cmap=cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2970"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4*3 + 26*4*5 + 26*26*8)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
